# llama_quantizations
Quantization implementations for the LLaMA-7B language model: Round-to-Nearest (RTN) and GPTQ algorithms to reduce model memory requirements from 16-bit to 4-bit
